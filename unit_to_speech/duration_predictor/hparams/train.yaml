###################################
# Experiment Parameters and setup #
###################################
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
model_name: !PLACEHOLDER
output_folder: !ref results/duration_predictor/<seed>/<model_name>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
epochs: 200 #300
keep_checkpoint_interval: 5



#################################
# Data files and pre-processing #
#################################
data_folder: /corpus/S2UT/16K
train_json: [
  # !ref <data_folder>/BLIZZARD11/metadata_train.json,
  # !ref <data_folder>/HiFi/metadata_train.json,
  !ref <data_folder>/LJ/metadata_train.json,
  #!ref <data_folder>/VCTK/metadata_train.json,
  !ref <data_folder>/ESD/metadata_train.json,
  #!ref <data_folder>/EmoV/metadata_train.json
  # !ref <data_folder>/IEMOCAP/metadata_train.json,
  # !ref <data_folder>/CREMAD/metadata_train.json
]
valid_json: [
  # !ref <data_folder>/BLIZZARD11/metadata_test.json,
  # !ref <data_folder>/HiFi/metadata_test.json,
  # !ref <data_folder>/LJ/metadata_test.json,
  #!ref <data_folder>/VCTK/metadata_test.json,
  !ref <data_folder>/ESD/metadata_test.json,
  #!ref <data_folder>/EmoV/metadata_test.json
  # !ref <data_folder>/IEMOCAP/metadata_test.json,
  # !ref <data_folder>/CREMAD/metadata_test.json
]

splits: ["train", "valid"]
units_folder: /ES2UT/data/discrete_units_freeze/mhubert/combined_mhubert
emotions_folder: /ES2UT/data/emotion_embeddings/wav2vec2-xlsr/combined_wav2vec2

n_tokens: 1000


################################
# Optimization Hyperparameters #
################################

learning_rate: 0.0001
weight_decay: 0.9999
batch_size: 16 #32

train_dataloader_opts:
  batch_size: !ref <batch_size>
  drop_last: False
  num_workers: 8
  collate_fn: !new:speechbrain.lobes.models.HifiGAN.DurationPredictorCollate
    padding_idx: !ref <n_tokens>

valid_dataloader_opts:
  batch_size: 1
  num_workers: 8
  collate_fn: !new:speechbrain.lobes.models.HifiGAN.DurationPredictorCollate
      padding_idx: !ref <n_tokens>

test_dataloader_opts:
  batch_size: 1
  num_workers: 8


################################
# Model Parameters and model   #
################################

in_channels: 128
num_embeddings: !ref <n_tokens>
embedding_dim: 128
var_pred_hidden_dim: 256
var_pred_kernel_size: 3
var_pred_dropout: 0.5


model: !new:speechbrain.lobes.models.HifiGAN.DurationPredictor
  in_channels: !ref <in_channels>
  num_embeddings: !ref <num_embeddings>
  embedding_dim: !ref <embedding_dim>
  var_pred_hidden_dim: !ref <var_pred_hidden_dim>
  var_pred_kernel_size: !ref <var_pred_kernel_size>
  var_pred_dropout: !ref <var_pred_dropout>

modules:
  model: !ref <model>

# Optimizer
opt_class: !name:torch.optim.Adam
  lr: !ref <learning_rate>
  #betas: [!ref <adam_b1>, !ref <adam_b2>]

#epoch object
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <epochs>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>

#checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>